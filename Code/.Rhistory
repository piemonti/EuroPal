shiny::runApp()
runApp()
runApp()
runApp()
load("/Users/pietromonti/Library/CloudStorage/Dropbox/Trajectory/hmm.RData")
# Extract the state sequence
state_sequence <- posterior(fitted_model, type = "viterbi")
library(depmixS4)
library(tidyverse)
library(ggplot2)
library(haven)
library(dplyr)
library(markovchain)
library(depmixS4)
library(tidyverse)
library(ggplot2)
library(haven)
library(dplyr)
library(markovchain)
library(igraph)
library(furrr)
library(gridExtra)
library(markovchain)
library(igraph)
library(tidyr)
# Extract the state sequence
state_sequence <- posterior(fitted_model, type = "viterbi")
summary(fitted_model)
# Extract transition probabilities
transitions <- lapply(fitted_model@transition, function(state_model) {
# Extract coefficients matrix
coef_matrix <- state_model@parameters$coefficients
intercept <- coef_matrix["(Intercept)", ]  # Intercept for each transition
probs <- exp(intercept) / sum(exp(intercept))  # Convert to probabilities
return(probs)
})
# Combine into a transition matrix
transition_matrix <- do.call(rbind, transitions)
# Print the transition matrix
print(transition_matrix)
# Extract state sequences
state_probs <- posterior(fitted_model)
# Function to analyze trajectories
analyze_trajectories <- function(state_probs, filtered_data) {
# Combine state assignments with original data
trajectories <- data.frame(
filtered_data,
state = state_probs[, "state"]  # Correctly access the state column
)
# Analyze common patterns
state_transitions <- trajectories %>%
group_by(mergeid) %>%
summarise(
trajectory = paste(state, collapse = "->"),
n_transitions = n_distinct(state) - 1,
.groups = 'drop'  # Avoid grouped output warning
)
return(state_transitions)
}
# Get trajectory analysis
trajectory_patterns <- analyze_trajectories(state_probs, filtered_data)
# Visualize state distributions over time
plot_state_distributions <- function(trajectories) {
ggplot(trajectories, aes(x = wave, fill = factor(state))) +
geom_bar(position = "fill") +
scale_fill_manual(
values = c( "#A6611A", "#DFC27D","#5A3A2E", "#D9D0C0", "#80CDC1", "#018571",
"#A6BDDB")
) +
labs(
title = "State Distribution Over Time",
x = "Time Point",
y = "Proportion",
fill = "State"
) +
theme_minimal()
}
# Apply the visualization function
trajectories_with_state <- data.frame(filtered_data, state = state_probs[, "state"])
plot_state_distributions(trajectories_with_state)
get_state_characteristics <- function(fitted_model, debug = TRUE) {
# Number of states
nstates <- fitted_model@nstates
if(debug) print(paste("Processing", nstates, "states"))
# Initialize list to store coefficients for each response variable
coef_list <- list()
responses <- c("cancre", "hibpe", "hearte", "diabe", "stroke", "lunge")
# Extract coefficients for each response variable first
for(resp_index in 1:6) {
resp_name <- responses[resp_index]
if(debug) print(paste("\nExtracting coefficients for", resp_name))
coeffs <- numeric(nstates)
for(state in 1:nstates) {
tryCatch({
model <- getmodel(fitted_model, which = "response", state = state, number = resp_index)
coef_val <- model@parameters$coefficients
if(debug) print(paste("State", state, "coefficient:", coef_val))
coeffs[state] <- coef_val
}, error = function(e) {
if(debug) print(paste("Error in state", state, ":", e$message))
coeffs[state] <- NA
})
}
coef_list[[resp_name]] <- coeffs
}
# Create the data frame
state_means <- data.frame(
State = 1:nstates
)
# Add coefficients to data frame
for(resp_name in responses) {
col_name <- paste0(resp_name, "_mean")
if(debug) {
print(paste("\nAdding", col_name))
print("Values:")
print(coef_list[[resp_name]])
}
state_means[[col_name]] <- coef_list[[resp_name]]
}
return(state_means)
}
state_characteristics <- get_state_characteristics(fitted_model)
print(state_characteristics)
plot_state_trajectories <- function(patient_data, state_probs) {
# Combine patient data with state probabilities
trajectories <- data.frame(
patient_data,
state = state_probs[, "state"]
)
# Aggregate data to calculate the proportion of individuals in each state at each wave point
state_summary <- trajectories %>%
group_by(wave, state) %>%
summarise(
count = n(),
.groups = 'drop'
) %>%
group_by(wave) %>%
mutate(proportion = count / sum(count)) %>%
ungroup()
# Plot the state trajectories over wave
ggplot(state_summary, aes(x = wave, y = proportion, color = factor(state), group = state)) +
geom_line(size = 1.2) +
scale_color_manual(
values = c(
"#A6611A", "#DFC27D","#5A3A2E", "#D9D0C0", "#80CDC1", "#018571",  "#A6BDDb" )
) +
labs(
title = "State Trajectories Over Wave",
x = "Wave Point",
y = "Proportion of Patients",
color = "State"
) +
theme_minimal()
}
# Apply the function to plot state trajectories
plot_state_trajectories(filtered_data, state_probs)
# Set up parallel processing
plan(multisession)
# Define the columns to sum over
columns_to_sum <- c("cancre", "hibpe", "hearte", "diabe", "stroke", "lunge")
# Convert haven_labelled columns to numeric
filtered_data <- filtered_data %>%
mutate(across(all_of(columns_to_sum), ~ as.numeric(as.character(.))))
# Parallelize the calculation
filtered_data <- filtered_data %>%
mutate(morbidity_count = future_pmap_dbl(
select(., all_of(columns_to_sum)),
~ sum(c(...), na.rm = TRUE)
))
# Reset to sequential execution
plan(sequential)
# Combine the state information with the morbidity data
trajectories_with_morbidity <- data.frame(
filtered_data,
state = state_probs[, "state"]
)
# Calculate mean morbidity count for each state and wave
morbidity_evolution <- trajectories_with_morbidity %>%
group_by(wave, state) %>%
summarise(
mean_morbidity = mean(morbidity_count, na.rm = TRUE),
se_morbidity = sd(morbidity_count, na.rm = TRUE) / sqrt(n()),
.groups = 'drop'
)
# Create the plot with error bands
ggplot(morbidity_evolution,
aes(x = as.numeric(wave),
y = mean_morbidity,
color = factor(state),
group = state)) +
geom_line(size = 1.2) +
geom_ribbon(aes(ymin = mean_morbidity - se_morbidity,
ymax = mean_morbidity + se_morbidity,
fill = factor(state)),
alpha = 0.2,
color = NA) +
scale_color_manual(
values = c("#A6611A", "#DFC27D", "#5A3A2E", "#D9D0C0",
"#80CDC1", "#018571", "#A6BDDB")
) +
scale_fill_manual(
values = c("#A6611A", "#DFC27D", "#5A3A2E", "#D9D0C0",
"#80CDC1", "#018571", "#A6BDDB")
) +
labs(
title = "Evolution of Average Morbidity Count by State",
subtitle = "Shaded areas represent 1 standard error",
x = "Wave",
y = "Average Number of Morbidities",
color = "State",
fill = "State"
) +
theme_minimal() +
theme(
legend.position = "right",
panel.grid.minor = element_blank(),
plot.title = element_text(face = "bold"),
axis.text = element_text(size = 10),
axis.title = element_text(size = 12)
)
# Create comprehensive summary table
morbidity_summary <- trajectories_with_morbidity %>%
group_by(wave, state) %>%
summarise(
mean_morbidity = round(mean(morbidity_count, na.rm = TRUE), 2),
sd_morbidity = round(sd(morbidity_count, na.rm = TRUE), 2),
median_morbidity = median(morbidity_count, na.rm = TRUE),
n_patients = n(),
min_morbidity = min(morbidity_count),
max_morbidity = max(morbidity_count),
.groups = 'drop'
) %>%
arrange(wave, state)
# Create a more readable format using knitr::kable
library(knitr)
kable(morbidity_summary,
col.names = c("Wave", "State", "Mean", "SD", "Median", "N", "Min", "Max"),
caption = "Summary Statistics of Morbidity Count by State and Wave",
format = "pipe",
digits = 2)
# Function to create Sankey diagram of state transitions
create_state_sankey <- function(trajectories_with_state) {
library(networkD3)
library(dplyr)
# Create pairs of consecutive waves
transitions <- trajectories_with_state %>%
group_by(mergeid) %>%
arrange(mergeid, wave) %>%
mutate(
next_state = lead(state),
next_wave = lead(wave)
) %>%
ungroup() %>%
filter(!is.na(next_state))  # Remove last wave which has no transition
# Create source-target pairs with wave information
links_df <- transitions %>%
mutate(
source_name = paste("Wave", wave, "State", state),
target_name = paste("Wave", next_wave, "State", next_state)
) %>%
count(source_name, target_name, name = "value") %>%
arrange(desc(value))
# Create unique nodes list
nodes_df <- data.frame(
name = unique(c(links_df$source_name, links_df$target_name))
)
# Convert source and target names to 0-based index
links_df$source <- match(links_df$source_name, nodes_df$name) - 1
links_df$target <- match(links_df$target_name, nodes_df$name) - 1
# Create the Sankey diagram
sankeyNetwork(
Links = links_df,
Nodes = nodes_df,
Source = "source",
Target = "target",
Value = "value",
NodeID = "name",
fontSize = 12,
nodeWidth = 30,
sinksRight = TRUE,
height = 600,
width = 1000
)
}
# Example usage:
# Assuming your data frame is called trajectories_with_state and contains:
# - mergeid: patient identifier
# - wave: time point
# - state: state assignment
# Create the Sankey diagram
sankey_plot <- create_state_sankey(trajectories_with_state)
# Display the plot
sankey_plot
